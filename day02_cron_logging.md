# ğŸ§  Linux å¤§ç¥ä¹‹è·¯ Day 2ï¼šè³‡æºæ§åˆ¶ãƒ»æ’ç¨‹ãƒ»Shell Script å¯¦æˆ°æŠ€å·§

## ğŸŒŸ ä¸»é¡Œä¸€ï¼šç¨‹å¼ & è³‡æºæ§åˆ¶â•Process & Resource Control

Data Engineer ç¸½æ˜¯æœƒåŸ·è¡Œè³‡æºå¯†é›†çš„ä»»å‹™ï¼Œä¾‹å¦‚ï¼š
- Spark Job
- Docker container
- Airflow DAG
- å¤§å‹ ETL script

### â›ï¸ å¸¸ç”¨æŒ‡ä»¤æ•´ç†

| æŒ‡ä»¤ | ç”¨é€” |
|------|------|
| `top` / `htop` | è§€å¯Ÿ CPU / è¨˜æ†¶é«” |
| `ps aux` / `ps -ef` | æŸ¥çœ‹åŸ·è¡Œä¸­çš„ç¨‹å¼ |
| `kill PID` | çµ‚æ­¢ç•¶æ‰çš„ç¨‹å¼ |
| `time python script.py` | æ¸¬è©¦åŸ·è¡Œæ™‚é–“ |
| `du -sh *` / `df -h` | çœ‹è³‡æ–™å¤¾å¤§å° / ç£ç¢Ÿç©ºé–“ |
| `iotop` | ç›£æ§ I/O ä½¿ç”¨æƒ…æ³ |
| `nmon` | åœ–å½¢åŒ–ç³»çµ±ç›£æ§ |

### ğŸ§¢ å¯¦éš›æ‡‰ç”¨å ´æ™¯

- `top`ï¼šè§€å¯Ÿ Spark Job åƒå…‰ CPU
- `ps aux | grep airflow`ï¼šæ‰¾åˆ°å¡ä½çš„ Airflow DAG
- `kill -9 PID`ï¼šå¼·åˆ¶çµ‚æ­¢éŒ¯èª¤æœå‹™
- `df -h`ï¼šå ±è¡¨æ²’è·‘å‡ºä¾†å› ç‚ºç£ç¢Ÿæ»¿äº†
- `time script.py`ï¼šåˆ†æè³‡æ–™è½‰æ› script èŠ±å¤šå°‘æ™‚é–“

### ğŸ” ç›£æ§å·¥å…·é€²éšä½¿ç”¨

#### htop é€²éšæ“ä½œ
| å¿«æ·éµ | åŠŸèƒ½ |
|-------|------|
| `F3` | æœå°‹ç¨‹åº |
| `F4` | éæ¿¾ç¨‹åº |
| `F5` | æ¨¹ç‹€çµæ§‹é¡¯ç¤º |
| `F6` | æ’åºé¸é … |
| `F9` | æ®ºæ­»ç¨‹åº |
| `u` | ä¾ä½¿ç”¨è€…éæ¿¾ |
| `t` | æ¨¹ç‹€/ä¸€èˆ¬é¡¯ç¤ºåˆ‡æ› |

#### iotop ç›£æ§ç£ç¢Ÿ I/O
```bash
sudo apt install iotop
sudo iotop                # å³æ™‚ç›£æ§ I/O ä½¿ç”¨æƒ…æ³
sudo iotop -o             # åªé¡¯ç¤ºæœ‰ I/O æ´»å‹•çš„ç¨‹åº
```

#### nmon åœ–å½¢åŒ–ç›£æ§
```bash
sudo apt install nmon
nmon                      # å•Ÿå‹•äº’å‹•å¼ç›£æ§
# æŒ‰ c é¡¯ç¤º CPU, m é¡¯ç¤ºè¨˜æ†¶é«”, d é¡¯ç¤ºç£ç¢Ÿ, n é¡¯ç¤ºç¶²è·¯
```

---

## âœ… Day 2 ç·´ç¿’æƒ…å¢ƒèˆ‡è§£æ³•èªªæ˜

### ğŸ“Š ä¸»é¡Œä¸€ï¼šç¨‹å¼ & è³‡æºæ§åˆ¶å¯¦æˆ°

#### ğŸ” æƒ…å¢ƒä¸€ï¼šæ‰¾å‡ºä¸¦çµ‚æ­¢ä½”ç”¨è³‡æºéé«˜çš„ç¨‹åº

**æƒ…å¢ƒèªªæ˜ï¼š**
ä½ çš„ Spark ä»»å‹™åŸ·è¡Œæ™‚é–“ç•°å¸¸é•·ï¼Œéœ€è¦æ‰¾å‡ºæ˜¯å“ªå€‹ç¨‹åºä½”ç”¨äº†éå¤šè³‡æºä¸¦é€²è¡Œè™•ç†ã€‚

```bash
# æ­¥é©Ÿ 1: ä½¿ç”¨ top è§€å¯Ÿç³»çµ±è³‡æº
top

# æ­¥é©Ÿ 2: æ‰¾åˆ° PID ä¸¦æŸ¥çœ‹è©³ç´°è³‡è¨Š
ps -ef | grep 12345

# æ­¥é©Ÿ 3: å˜—è©¦æ­£å¸¸çµ‚æ­¢ç¨‹åº
kill 12345

# æ­¥é©Ÿ 4: å¦‚æœç¨‹åºç„¡æ³•æ­£å¸¸çµ‚æ­¢ï¼Œå¼·åˆ¶çµ‚æ­¢
kill -9 12345
```

**æŠ€è¡“è§£é‡‹ï¼š**
- `top`ï¼šå³æ™‚é¡¯ç¤ºç³»çµ±è³‡æºä½¿ç”¨æƒ…æ³ï¼ŒæŒ‰ `P` å¯ä¾ CPU ä½¿ç”¨ç‡æ’åº
- `ps -ef | grep PID`ï¼šæŸ¥çœ‹ç‰¹å®šç¨‹åºçš„è©³ç´°è³‡è¨Šï¼ŒåŒ…æ‹¬å•Ÿå‹•å‘½ä»¤
- `kill PID`ï¼šç™¼é€ SIGTERM ä¿¡è™Ÿï¼Œè«‹æ±‚ç¨‹åºæ­£å¸¸çµ‚æ­¢
- `kill -9 PID`ï¼šç™¼é€ SIGKILL ä¿¡è™Ÿï¼Œå¼·åˆ¶çµ‚æ­¢ç¨‹åºï¼ˆæœ€å¾Œæ‰‹æ®µï¼‰

#### ğŸ” æƒ…å¢ƒäºŒï¼šåˆ†æç£ç¢Ÿç©ºé–“å•é¡Œ

**æƒ…å¢ƒèªªæ˜ï¼š**
æŸå€‹ ETL ä»»å‹™çªç„¶å¤±æ•—ï¼ŒéŒ¯èª¤è¨Šæ¯é¡¯ç¤ºã€ŒNo space left on deviceã€ï¼Œéœ€è¦å¿«é€Ÿæ‰¾å‡ºä½”ç”¨ç©ºé–“çš„ç›®éŒ„ã€‚

```bash
# æ­¥é©Ÿ 1: æª¢æŸ¥ç£ç¢Ÿä½¿ç”¨æƒ…æ³
df -h

# æ­¥é©Ÿ 2: æ‰¾å‡ºå¤§å‹ç›®éŒ„
du -sh /*

# æ­¥é©Ÿ 3: æ·±å…¥åˆ†æç‰¹å®šç›®éŒ„
cd /var/log
du -sh * | sort -hr | head -10

# æ­¥é©Ÿ 4: æ¸…ç†ä¸éœ€è¦çš„æª”æ¡ˆ
rm -f old_logs/*.gz
```

**æŠ€è¡“è§£é‡‹ï¼š**
- `df -h`ï¼šä»¥äººé¡å¯è®€æ ¼å¼é¡¯ç¤ºæ‰€æœ‰æ›è¼‰é»çš„ç©ºé–“ä½¿ç”¨æƒ…æ³
- `du -sh /*`ï¼šé¡¯ç¤ºæ ¹ç›®éŒ„ä¸‹å„å€‹ç›®éŒ„çš„ç¸½å¤§å°
- `sort -hr`ï¼šä¾å¤§å°æ’åºï¼ˆh è¡¨ç¤ºäººé¡å¯è®€ï¼Œr è¡¨ç¤ºé™åºï¼‰
- `head -10`ï¼šåªé¡¯ç¤ºå‰ 10 å€‹æœ€å¤§çš„é …ç›®

#### ğŸ” æƒ…å¢ƒä¸‰ï¼šç›£æ§ I/O æ•ˆèƒ½å•é¡Œ

**æƒ…å¢ƒèªªæ˜ï¼š**
è³‡æ–™è™•ç†ä»»å‹™åŸ·è¡Œç·©æ…¢ï¼Œæ‡·ç–‘æ˜¯ I/O ç“¶é ¸å°è‡´ï¼Œéœ€è¦æ‰¾å‡ºå“ªäº›ç¨‹åºä½”ç”¨äº†å¤§é‡ I/Oã€‚

```bash
# æ­¥é©Ÿ 1: å®‰è£ä¸¦å•Ÿå‹• iotop
sudo apt install iotop
sudo iotop -o

# æ­¥é©Ÿ 2: è§€å¯Ÿ I/O ä½¿ç”¨æƒ…æ³
# æ‰¾å‡º I/O è®€å¯«é‡å¤§çš„ç¨‹åº

# æ­¥é©Ÿ 3: èª¿æ•´ç¨‹åºå„ªå…ˆç´š
ionice -c2 -n7 -p 12345
```

**æŠ€è¡“è§£é‡‹ï¼š**
- `iotop -o`ï¼šåªé¡¯ç¤ºæœ‰ I/O æ´»å‹•çš„ç¨‹åºï¼Œä¾¿æ–¼æ‰¾å‡ºå•é¡Œ
- `ionice`ï¼šèª¿æ•´ç¨‹åºçš„ I/O å„ªå…ˆç´šï¼Œæ¸›å°‘å°ç³»çµ±çš„å½±éŸ¿
  - `-c2`ï¼šä½¿ç”¨æœ€ä½³æ•ˆèƒ½èª¿åº¦é¡åˆ¥
  - `-n7`ï¼šè¨­å®šè¼ƒä½çš„å„ªå…ˆç´šï¼ˆ0-7ï¼Œ7 æœ€ä½ï¼‰
  - `-p PID`ï¼šæŒ‡å®šè¦èª¿æ•´çš„ç¨‹åº ID

---

## ğŸŒŸ ä¸»é¡ŒäºŒï¼šæ’ç¨‹èˆ‡è‡ªå‹•åŒ–ï¼ˆcronï¼‰

è®“ä½ çš„ç¨‹å¼ã€Œå®šæ™‚è‡ªå‹•åŸ·è¡Œã€ï¼Œå¸¸ç”¨æ–¼ï¼š
- æ¯å¤©è·‘å ±è¡¨
- æ¯å°æ™‚åŒæ­¥è³‡æ–™
- æ¯æœˆæ¸…ç† log

### ğŸ“˜ cron åŸºç¤èªæ³•

```
* * * * * command
â”‚ â”‚ â”‚ â”‚ â””â”€ é€±æœŸ (0=Sun)
â”‚ â”‚ â”‚ â””â”€â”€ æœˆä»½
â”‚ â”‚ â””â”€â”€â”€ æœˆå…§æ—¥æœŸ
â”‚ â””â”€â”€â”€â”€â”€ å°æ™‚ (0â€“23)
â””â”€â”€â”€â”€â”€â”€â”€ åˆ†é˜ (0â€“59)
```

### ğŸ›  å¸¸ç”¨æŒ‡ä»¤

| æŒ‡ä»¤ | ç”¨é€” |
|------|------|
| `crontab -e` | ç·¨è¼¯æ’ç¨‹ä»»å‹™ |
| `crontab -l` | æŸ¥çœ‹ä»»å‹™æ¸…å–® |
| `>> log 2>&1` | å°‡è¼¸å‡ºå¯«å…¥ logï¼ˆå«éŒ¯èª¤ï¼‰ |

### â—cron æ³¨æ„äº‹é …ï¼ˆæ–°æ‰‹åœ°é›·ï¼‰

#### ç’°å¢ƒè®Šæ•¸ä¸åŒ
cron è·‘çš„ç’°å¢ƒè®Šæ•¸æ¯”ä½ å¹³å¸¸é–‹ terminal å°‘ï¼åƒ Python venvã€PATHã€PYTHONPATH ç­‰éƒ½å¯èƒ½è¦æ‰‹å‹•æŒ‡å®šã€‚

```bash
# åœ¨ crontab ä¸­è¨­å®šç’°å¢ƒè®Šæ•¸
PATH=/usr/local/bin:/usr/bin:/bin
PYTHONPATH=/path/to/your/project

# æˆ–åœ¨è…³æœ¬ä¸­è¨­å®š
0 9 * * * cd /path/to/project && source venv/bin/activate && python script.py
```

#### script é–‹é ­è¨˜å¾—è¨­å®š shebang
```bash
#!/bin/bash
```
ä¸ç„¶å¯èƒ½ç„¡æ³•æ­£ç¢ºåŸ·è¡Œã€‚

#### è¨˜å¾— log è¦å¯«å®Œæ•´è·¯å¾‘
```bash
0 9 * * * /path/to/script.sh >> /path/to/logs/cron.log 2>&1
```
å¦å‰‡éŒ¯èª¤ä½ ä¹Ÿä¸çŸ¥é“ç™¼ç”Ÿäº†ä»€éº¼äº‹ã€‚

#### æ¸¬è©¦ cron è…³æœ¬æŠ€å·§
```bash
# 1. å…ˆæ‰‹å‹•åŸ·è¡Œç¢ºèªæ²’å•é¡Œ
bash /path/to/script.sh

# 2. ç¢ºèªæ¬Šé™
chmod +x /path/to/script.sh

# 3. ä½¿ç”¨çµ•å°è·¯å¾‘
which python  # æ‰¾å‡º python çš„çµ•å°è·¯å¾‘
```

### ğŸ§ª ç¯„ä¾‹ä»»å‹™

| æ’ç¨‹æ™‚é–“ | æŒ‡ä»¤ |
|---------|------|
| æ¯å¤©æ—©ä¸Š 9 é» | 0 9 * * * |
| æ¯ 5 åˆ†é˜ | */5 * * * * |
| æ¯é€±ä¸€æ—©ä¸Š 8 é» | 0 8 * * 1 |
| æ¯æœˆ 1 è™Ÿ 0 é» | 0 0 1 * * |

```bash
0 9 * * * bash ~/scripts/run_report.sh >> logs/cron_$(date +\%F).log 2>&1
```

ğŸ‘‰ log æª”åæ¯æ—¥ä¸åŒ  
ğŸ‘‰ `\%F` è¦ escape `%` æ‰èƒ½åœ¨ cron ä¸­ç”Ÿæ•ˆ

### ğŸ“† ä¸»é¡ŒäºŒï¼šæ’ç¨‹èˆ‡è‡ªå‹•åŒ–å¯¦æˆ°

#### ğŸ” æƒ…å¢ƒä¸€ï¼šæ¯æ—¥è‡ªå‹•å‚™ä»½è³‡æ–™åº«

**æƒ…å¢ƒèªªæ˜ï¼š**
ä½ éœ€è¦æ¯å¤©å‡Œæ™¨ 2 é»è‡ªå‹•å‚™ä»½ PostgreSQL è³‡æ–™åº«ï¼Œä¸¦ä¿ç•™æœ€è¿‘ 7 å¤©çš„å‚™ä»½ã€‚

```bash
# æ­¥é©Ÿ 1: å»ºç«‹å‚™ä»½è…³æœ¬ db_backup.sh
cat > ~/scripts/db_backup.sh << 'EOF'
#!/bin/bash

BACKUP_DIR="/backup/postgres"
DATETIME=$(date +%Y%m%d_%H%M%S)
DB_NAME="mydb"

# ç¢ºä¿å‚™ä»½ç›®éŒ„å­˜åœ¨
mkdir -p $BACKUP_DIR

# åŸ·è¡Œå‚™ä»½
pg_dump $DB_NAME | gzip > "$BACKUP_DIR/${DB_NAME}_${DATETIME}.sql.gz"

# åˆªé™¤ 7 å¤©å‰çš„å‚™ä»½
find $BACKUP_DIR -name "${DB_NAME}_*.sql.gz" -mtime +7 -delete

echo "å‚™ä»½å®Œæˆ: $BACKUP_DIR/${DB_NAME}_${DATETIME}.sql.gz"
EOF

# æ­¥é©Ÿ 2: è¨­å®šåŸ·è¡Œæ¬Šé™
chmod +x ~/scripts/db_backup.sh

# æ­¥é©Ÿ 3: è¨­å®š crontab
crontab -e
# åŠ å…¥ä»¥ä¸‹è¡Œ
0 2 * * * /home/user/scripts/db_backup.sh >> /home/user/logs/backup_$(date +\%F).log 2>&1
```

**æŠ€è¡“è§£é‡‹ï¼š**
- `crontab -e`ï¼šç·¨è¼¯ç•¶å‰ç”¨æˆ¶çš„ cron ä»»å‹™
- `0 2 * * *`ï¼šæ¯å¤©å‡Œæ™¨ 2 é»åŸ·è¡Œ
- `pg_dump`ï¼šPostgreSQL è³‡æ–™åº«å‚™ä»½å·¥å…·
- `find ... -mtime +7 -delete`ï¼šæ‰¾å‡ºä¸¦åˆªé™¤ 7 å¤©å‰çš„æª”æ¡ˆ
- `>> /home/user/logs/backup_$(date +\%F).log 2>&1`ï¼šå°‡æ¨™æº–è¼¸å‡ºå’ŒéŒ¯èª¤è¼¸å‡ºè¨˜éŒ„åˆ°æ—¥æœŸå‘½åçš„æ—¥èªŒæª”

#### ğŸ” æƒ…å¢ƒäºŒï¼šç›£æ§æœå‹™ç‹€æ…‹ä¸¦è‡ªå‹•é‡å•Ÿ

**æƒ…å¢ƒèªªæ˜ï¼š**
ä½ æœ‰ä¸€å€‹é‡è¦çš„ API æœå‹™éœ€è¦ç¢ºä¿ 24/7 é‹è¡Œï¼Œéœ€è¦æ¯ 5 åˆ†é˜æª¢æŸ¥ä¸€æ¬¡ï¼Œå¦‚æœæœå‹™åœæ­¢å‰‡è‡ªå‹•é‡å•Ÿã€‚

```bash
# æ­¥é©Ÿ 1: å»ºç«‹ç›£æ§è…³æœ¬ monitor_service.sh
cat > ~/scripts/monitor_service.sh << 'EOF'
#!/bin/bash

SERVICE_NAME="my-api-service"
LOG_FILE="/var/log/service_monitor.log"

# æª¢æŸ¥æœå‹™ç‹€æ…‹
if ! systemctl is-active --quiet $SERVICE_NAME; then
    echo "$(date): $SERVICE_NAME å·²åœæ­¢ï¼Œå˜—è©¦é‡å•Ÿ..." >> $LOG_FILE
    
    # å˜—è©¦é‡å•Ÿæœå‹™
    systemctl restart $SERVICE_NAME
    
    # æª¢æŸ¥é‡å•Ÿæ˜¯å¦æˆåŠŸ
    if systemctl is-active --quiet $SERVICE_NAME; then
        echo "$(date): $SERVICE_NAME é‡å•ŸæˆåŠŸ" >> $LOG_FILE
        # ç™¼é€æˆåŠŸé€šçŸ¥
        curl -X POST -H "Content-Type: application/json" \
             -d '{"text":"æœå‹™å·²è‡ªå‹•é‡å•ŸæˆåŠŸ"}' \
             https://hooks.slack.com/services/YOUR_WEBHOOK_URL
    else
        echo "$(date): $SERVICE_NAME é‡å•Ÿå¤±æ•—ï¼Œéœ€è¦äººå·¥ä»‹å…¥" >> $LOG_FILE
        # ç™¼é€å¤±æ•—è­¦å ±
        curl -X POST -H "Content-Type: application/json" \
             -d '{"text":"è­¦å‘Šï¼šæœå‹™é‡å•Ÿå¤±æ•—ï¼Œè«‹ç«‹å³æª¢æŸ¥ï¼"}' \
             https://hooks.slack.com/services/YOUR_WEBHOOK_URL
    fi
fi
EOF

# æ­¥é©Ÿ 2: è¨­å®šåŸ·è¡Œæ¬Šé™
chmod +x ~/scripts/monitor_service.sh

# æ­¥é©Ÿ 3: è¨­å®š crontab
crontab -e
# åŠ å…¥ä»¥ä¸‹è¡Œ
*/5 * * * * /home/user/scripts/monitor_service.sh
```

**æŠ€è¡“è§£é‡‹ï¼š**
- `*/5 * * * *`ï¼šæ¯ 5 åˆ†é˜åŸ·è¡Œä¸€æ¬¡
- `systemctl is-active --quiet`ï¼šéœé»˜æª¢æŸ¥æœå‹™æ˜¯å¦é‹è¡Œä¸­
- `systemctl restart`ï¼šé‡å•Ÿç³»çµ±æœå‹™
- `curl -X POST`ï¼šç™¼é€ webhook é€šçŸ¥åˆ° Slack æˆ–å…¶ä»–å¹³å°

#### ğŸ” æƒ…å¢ƒä¸‰ï¼šå®šæ™‚è³‡æ–™åŒæ­¥èˆ‡æ¸…ç†

**æƒ…å¢ƒèªªæ˜ï¼š**
ä½ éœ€è¦æ¯å°æ™‚å¾å¤–éƒ¨ API ç²å–æ–°æ•¸æ“šï¼Œè™•ç†å¾Œå­˜å…¥æœ¬åœ°è³‡æ–™åº«ï¼Œä¸¦åœ¨æ¯é€±æ—¥æ¸…ç†èˆŠæ•¸æ“šã€‚

```bash
# å°æ™‚ä»»å‹™ï¼šè³‡æ–™åŒæ­¥
0 * * * * cd /path/to/project && source venv/bin/activate && python sync_data.py >> /var/log/data_sync/hourly_$(date +\%F).log 2>&1

# é€±ä»»å‹™ï¼šæ¸…ç†èˆŠæ•¸æ“š
0 0 * * 0 cd /path/to/project && source venv/bin/activate && python cleanup_old_data.py --days 30 >> /var/log/data_sync/cleanup_$(date +\%F).log 2>&1
```

**æŠ€è¡“è§£é‡‹ï¼š**
- `0 * * * *`ï¼šæ¯å°æ™‚æ•´é»åŸ·è¡Œ
- `0 0 * * 0`ï¼šæ¯é€±æ—¥åˆå¤œåŸ·è¡Œ
- `cd /path/to/project && source venv/bin/activate`ï¼šåˆ‡æ›åˆ°å°ˆæ¡ˆç›®éŒ„ä¸¦å•Ÿå‹•è™›æ“¬ç’°å¢ƒ
- `--days 30`ï¼šå‚³éåƒæ•¸çµ¦æ¸…ç†è…³æœ¬ï¼ŒæŒ‡å®šæ¸…ç† 30 å¤©å‰çš„æ•¸æ“š

---

## ğŸŒŸ ä¸»é¡Œä¸‰ï¼šShell Script æµç¨‹æ§åˆ¶æŠ€å·§

è®“ä½ çš„ script æ›´éˆæ´»ã€æ›´åƒå°å‹æ‡‰ç”¨ç¨‹å¼ï¼

### â›ï¸ æŠ€å·§æ¸…å–®

| æŠ€è¡“ | ç”¨é€” |
|------|------|
| `if [ ... ]` | åˆ¤æ–·æ¢ä»¶ |
| `for`, `while` | è¿´åœˆæ§åˆ¶æµç¨‹ |
| `source .venv/bin/activate` | å•Ÿå‹•è™›æ“¬ç’°å¢ƒ |
| `log_file="$(date +%F).log"` | å‹•æ…‹ log æª”å‘½å |
| `curl + jq` | æ‰“ API + è§£æ JSON |
| `exit 1` | éŒ¯èª¤æ™‚ä¸­æ­¢æµç¨‹ |

### ğŸ§ª å¯¦ä½œç¯„ä¾‹

```bash
if [ $((10#$hour % 2)) -eq 0 ]; then
    echo "YES"
else
    echo "NO"
fi
```

æ­é…ï¼š
- `curl` ç™¼é€šçŸ¥
- `grep` æ‰¾ ERROR å†åœæ­¢æµç¨‹

### ğŸš€ Shell Script é€²éšæŠ€å·§

#### å‡½æ•¸å®šç¾©èˆ‡ä½¿ç”¨
```bash
# å®šç¾©å‡½æ•¸
function check_status {
    if [ $1 -eq 0 ]; then
        echo "æˆåŠŸ: $2"
        return 0
    else
        echo "å¤±æ•—: $2"
        return 1
    fi
}

# å‘¼å«å‡½æ•¸
check_status $? "è³‡æ–™è™•ç†"
```

#### éŒ¯èª¤è™•ç†èˆ‡é€€å‡ºç¢¼æª¢æŸ¥
```bash
set -e                   # ä»»ä½•æŒ‡ä»¤éŒ¯èª¤å°±ä¸­æ­¢è…³æœ¬
trap 'echo "éŒ¯èª¤ç™¼ç”Ÿæ–¼ç¬¬ $LINENO è¡Œ"; exit 1' ERR  # éŒ¯èª¤è™•ç†

# æª¢æŸ¥ä¸Šä¸€å€‹æŒ‡ä»¤çš„é€€å‡ºç¢¼
command
if [ $? -ne 0 ]; then
    echo "æŒ‡ä»¤å¤±æ•—ï¼Œé–‹å§‹æ¸…ç†..."
    # æ¸…ç†æ“ä½œ
    exit 1
fi
```

#### åƒæ•¸è§£æ
```bash
while getopts "f:d:h" opt; do
  case $opt in
    f) file="$OPTARG" ;;
    d) date="$OPTARG" ;;
    h) echo "ä½¿ç”¨æ–¹æ³•: $0 -f <æª”æ¡ˆ> -d <æ—¥æœŸ>"; exit 0 ;;
    *) echo "æœªçŸ¥åƒæ•¸"; exit 1 ;;
  esac
done
```

#### ä¸¦è¡Œè™•ç†
```bash
# å•Ÿå‹•èƒŒæ™¯ä»»å‹™
for i in {1..5}; do
    process_data "file$i" &
    pids[$i]=$!
done

# ç­‰å¾…æ‰€æœ‰ä»»å‹™å®Œæˆ
for pid in ${pids[*]}; do
    wait $pid
done
```

### ğŸ’¼ ä¸»é¡Œä¸‰ï¼šShell Script æµç¨‹æ§åˆ¶å¯¦æˆ°

#### ğŸ” æƒ…å¢ƒä¸€ï¼šfor è®€å–è³‡æ–™å¤¾å…§æ‰€æœ‰æª”æ¡ˆï¼šæ‰¹æ¬¡è™•ç†ä»»å‹™

**æƒ…å¢ƒèªªæ˜ï¼š**
ä½ æœ‰å¤šå€‹ `.csv` æª”æ¡ˆåœ¨è³‡æ–™å¤¾ä¸­ï¼Œæƒ³è¦è‡ªå‹•è®€å–æ¯ä¸€å€‹æª”æ¡ˆä¸¦äº¤çµ¦ Python script è™•ç†ã€‚

```bash
#!/bin/bash
# process_all_csv.sh

DATA_DIR="/path/to/data"
OUTPUT_DIR="/path/to/output"
LOG_FILE="processing_$(date +%F).log"

# ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
mkdir -p $OUTPUT_DIR

# è¨˜éŒ„é–‹å§‹æ™‚é–“
echo "[é–‹å§‹è™•ç†] $(date)" > $LOG_FILE

# è¨ˆç®—æª”æ¡ˆæ•¸é‡
TOTAL_FILES=$(find $DATA_DIR -name "*.csv" | wc -l)
echo "ç™¼ç¾ $TOTAL_FILES å€‹ CSV æª”æ¡ˆè¦è™•ç†" >> $LOG_FILE

# è¨ˆæ•¸å™¨
COUNT=0

# éæ­·æ‰€æœ‰ CSV æª”æ¡ˆ
for file in $DATA_DIR/*.csv; do
    filename=$(basename "$file")
    COUNT=$((COUNT + 1))
    
    echo "[$COUNT/$TOTAL_FILES] è™•ç† $filename..." >> $LOG_FILE
    
    # å‘¼å« Python è™•ç†è…³æœ¬
    python3 process_csv.py "$file" "$OUTPUT_DIR" >> $LOG_FILE 2>&1
    
    # æª¢æŸ¥è™•ç†çµæœ
    if [ $? -eq 0 ]; then
        echo "  âœ… æˆåŠŸè™•ç† $filename" >> $LOG_FILE
    else
        echo "  âŒ è™•ç† $filename å¤±æ•—" >> $LOG_FILE
    fi
done

echo "[å®Œæˆ] $(date) - å…±è™•ç† $COUNT å€‹æª”æ¡ˆ" >> $LOG_FILE
```

**æŠ€è¡“è§£é‡‹ï¼š**
- `for file in $DATA_DIR/*.csv`ï¼šloop éæ­·æ‰€æœ‰ csv æª”æ¡ˆ
- `basename "$file"`ï¼šå–å¾—æª”æ¡ˆåç¨±ï¼ˆä¸å«è·¯å¾‘ï¼‰
- `python3 process_csv.py "$file" "$OUTPUT_DIR"`ï¼šæ¯å€‹æª”æ¡ˆä½œç‚ºåƒæ•¸äº¤çµ¦ script è™•ç†
- `if [ $? -eq 0 ]`ï¼šæª¢æŸ¥ä¸Šä¸€å€‹å‘½ä»¤çš„åŸ·è¡Œçµæœï¼ˆ0 è¡¨ç¤ºæˆåŠŸï¼‰
- é©ç”¨æ–¼æ¯æ—¥è³‡æ–™æ‰¹æ¬¡è™•ç†ã€å ±è¡¨ç”Ÿæˆä»»å‹™

#### ğŸ” æƒ…å¢ƒäºŒï¼šwhile loop æ¨¡æ“¬ç›£æ§ä»»å‹™ï¼ˆlog ç›£æ§ã€è‡ªå‹•é‡è©¦ï¼‰

**æƒ…å¢ƒèªªæ˜ï¼š**
ä½ å¸Œæœ›å®šæœŸæƒææŸå€‹ log æª”æ¡ˆæ˜¯å¦å‡ºç¾ã€ŒERRORã€ï¼Œå¦‚æœæœ‰å°±è§¸ç™¼è­¦å‘Šæˆ–ä¸­æ­¢æµç¨‹ã€‚

```bash
#!/bin/bash
# monitor_log.sh

LOG_FILE="/var/log/myapp/pipeline.log"
CHECK_INTERVAL=10  # æ¯ 10 ç§’æª¢æŸ¥ä¸€æ¬¡
MAX_ERRORS=3       # æœ€å¤šå…è¨± 3 æ¬¡éŒ¯èª¤

echo "[é–‹å§‹ç›£æ§] $(date) - æª¢æŸ¥æª”æ¡ˆ: $LOG_FILE"

error_count=0

while true; do
  if grep -q "ERROR" "$LOG_FILE"; then
    error_count=$((error_count + 1))
    echo "[è­¦å‘Š] $(date) - åµæ¸¬åˆ°éŒ¯èª¤ ($error_count/$MAX_ERRORS)"
    
    # æ“·å–éŒ¯èª¤è¨Šæ¯
    error_msg=$(grep "ERROR" "$LOG_FILE" | tail -1)
    echo "  éŒ¯èª¤è¨Šæ¯: $error_msg"
    
    # ç™¼é€è­¦å ±
    curl -s -X POST -H "Content-Type: application/json" \
         -d "{\"text\":\"Pipeline éŒ¯èª¤: $error_msg\"}" \
         https://hooks.slack.com/services/YOUR_WEBHOOK_URL > /dev/null
    
    # å¦‚æœéŒ¯èª¤æ¬¡æ•¸è¶…éé™åˆ¶ï¼Œåœæ­¢ç›£æ§
    if [ $error_count -ge $MAX_ERRORS ]; then
      echo "[åœæ­¢] $(date) - éŒ¯èª¤æ¬¡æ•¸è¶…éä¸Šé™ ($MAX_ERRORS)ï¼ŒçµæŸç›£æ§"
      exit 1
    fi
  fi
  
  # ç­‰å¾…ä¸€æ®µæ™‚é–“å†æª¢æŸ¥
  sleep $CHECK_INTERVAL
done
```

**æŠ€è¡“è§£é‡‹ï¼š**
- `while true`ï¼šç„¡é™ç›£æ§è¿´åœˆ
- `grep -q "ERROR"`ï¼šéœé»˜æœå°‹æ˜¯å¦æœ‰åŒ…å«ç‰¹å®šé—œéµå­—ï¼ˆé€™è£¡æ˜¯ ERRORï¼‰
- `error_count=$((error_count + 1))`ï¼šè¨ˆç®—éŒ¯èª¤æ¬¡æ•¸
- `curl -s -X POST`ï¼šç™¼é€ webhook é€šçŸ¥
- `sleep $CHECK_INTERVAL`ï¼šæ¯ 10 ç§’æª¢æŸ¥ä¸€æ¬¡ï¼Œé¿å… CPU éåº¦æ¶ˆè€—

#### ğŸ” æƒ…å¢ƒä¸‰ï¼šä½¿ç”¨å‡½æ•¸èˆ‡åƒæ•¸è§£æå»ºç«‹é€šç”¨å·¥å…·

**æƒ…å¢ƒèªªæ˜ï¼š**
ä½ éœ€è¦å»ºç«‹ä¸€å€‹é€šç”¨çš„è³‡æ–™å‚™ä»½å·¥å…·ï¼Œå¯ä»¥æ¥å—ä¸åŒçš„åƒæ•¸ä¾†å‚™ä»½ä¸åŒçš„ç›®éŒ„æˆ–è³‡æ–™åº«ã€‚

```bash
#!/bin/bash
# backup_tool.sh

# é¡¯ç¤ºä½¿ç”¨æ–¹æ³•
show_usage() {
    echo "ç”¨æ³•: $0 [-t type] [-s source] [-d destination] [-r retention_days]"
    echo "  -t: å‚™ä»½é¡å‹ (files æˆ– database)"
    echo "  -s: ä¾†æºè·¯å¾‘æˆ–è³‡æ–™åº«åç¨±"
    echo "  -d: ç›®æ¨™è·¯å¾‘"
    echo "  -r: ä¿ç•™å¤©æ•¸ (é è¨­: 7)"
    echo "  -h: é¡¯ç¤ºæ­¤èªªæ˜"
    exit 1
}

# å‚™ä»½æª”æ¡ˆ
backup_files() {
    local source=$1
    local dest=$2
    local filename="files_backup_$(date +%Y%m%d_%H%M%S).tar.gz"
    
    echo "[å‚™ä»½æª”æ¡ˆ] ä¾†æº: $source"
    echo "[å‚™ä»½æª”æ¡ˆ] ç›®æ¨™: $dest/$filename"
    
    # å‰µå»ºç›®æ¨™ç›®éŒ„
    mkdir -p "$dest"
    
    # åŸ·è¡Œå‚™ä»½
    tar -czf "$dest/$filename" -C "$(dirname "$source")" "$(basename "$source")"
    
    if [ $? -eq 0 ]; then
        echo "[å‚™ä»½æª”æ¡ˆ] âœ… æˆåŠŸ"
        return 0
    else
        echo "[å‚™ä»½æª”æ¡ˆ] âŒ å¤±æ•—"
        return 1
    fi
}

# å‚™ä»½è³‡æ–™åº«
backup_database() {
    local dbname=$1
    local dest=$2
    local filename="db_backup_$(date +%Y%m%d_%H%M%S).sql.gz"
    
    echo "[å‚™ä»½è³‡æ–™åº«] è³‡æ–™åº«: $dbname"
    echo "[å‚™ä»½è³‡æ–™åº«] ç›®æ¨™: $dest/$filename"
    
    # å‰µå»ºç›®æ¨™ç›®éŒ„
    mkdir -p "$dest"
    
    # åŸ·è¡Œå‚™ä»½
    pg_dump "$dbname" | gzip > "$dest/$filename"
    
    if [ $? -eq 0 ]; then
        echo "[å‚™ä»½è³‡æ–™åº«] âœ… æˆåŠŸ"
        return 0
    else
        echo "[å‚™ä»½è³‡æ–™åº«] âŒ å¤±æ•—"
        return 1
    fi
}

# æ¸…ç†èˆŠå‚™ä»½
cleanup_old_backups() {
    local backup_dir=$1
    local days=$2
    local type=$3
    
    echo "[æ¸…ç†] ç§»é™¤ $days å¤©å‰çš„ $type å‚™ä»½"
    
    if [ "$type" == "files" ]; then
        find "$backup_dir" -name "files_backup_*.tar.gz" -mtime +$days -delete
    else
        find "$backup_dir" -name "db_backup_*.sql.gz" -mtime +$days -delete
    fi
    
    echo "[æ¸…ç†] å®Œæˆ"
}

# é è¨­å€¼
TYPE=""
SOURCE=""
DEST=""
RETENTION=7

# è§£æå‘½ä»¤åˆ—åƒæ•¸
while getopts "t:s:d:r:h" opt; do
    case $opt in
        t) TYPE=$OPTARG ;;
        s) SOURCE=$OPTARG ;;
        d) DEST=$OPTARG ;;
        r) RETENTION=$OPTARG ;;
        h) show_usage ;;
        *) show_usage ;;
    esac
done

# æª¢æŸ¥å¿…è¦åƒæ•¸
if [ -z "$TYPE" ] || [ -z "$SOURCE" ] || [ -z "$DEST" ]; then
    echo "[éŒ¯èª¤] ç¼ºå°‘å¿…è¦åƒæ•¸"
    show_usage
fi

# åŸ·è¡Œå‚™ä»½
echo "[é–‹å§‹] $(date) - å‚™ä»½é¡å‹: $TYPE"

case $TYPE in
    "files")
        backup_files "$SOURCE" "$DEST"
        RESULT=$?
        ;;
    "database")
        backup_database "$SOURCE" "$DEST"
        RESULT=$?
        ;;
    *)
        echo "[éŒ¯èª¤] ä¸æ”¯æ´çš„å‚™ä»½é¡å‹: $TYPE"
        exit 1
        ;;
esac

# æ¸…ç†èˆŠå‚™ä»½
if [ $RESULT -eq 0 ]; then
    cleanup_old_backups "$DEST" "$RETENTION" "$TYPE"
    echo "[å®Œæˆ] $(date) - å‚™ä»½èˆ‡æ¸…ç†å®Œæˆ"
    exit 0
else
    echo "[å¤±æ•—] $(date) - å‚™ä»½å¤±æ•—ï¼Œä¸åŸ·è¡Œæ¸…ç†"
    exit 1
fi
```

**ä½¿ç”¨ç¯„ä¾‹ï¼š**
```bash
# å‚™ä»½æª”æ¡ˆ
./backup_tool.sh -t files -s /path/to/important/data -d /backup/files -r 14

# å‚™ä»½è³‡æ–™åº«
./backup_tool.sh -t database -s mydb -d /backup/databases -r 30
```

**æŠ€è¡“è§£é‡‹ï¼š**
- `function name() { ... }`ï¼šå®šç¾©å¯é‡è¤‡ä½¿ç”¨çš„å‡½æ•¸
- `getopts "t:s:d:r:h" opt`ï¼šè§£æå‘½ä»¤åˆ—åƒæ•¸ï¼Œå†’è™Ÿè¡¨ç¤ºéœ€è¦å€¼
- `case $TYPE in ... esac`ï¼šæ ¹æ“šä¸åŒåƒæ•¸åŸ·è¡Œä¸åŒæ“ä½œ
- `local variable`ï¼šå®šç¾©å‡½æ•¸å…§éƒ¨è®Šæ•¸ï¼Œé¿å…å½±éŸ¿å…¨å±€è®Šæ•¸
- `$?`ï¼šæª¢æŸ¥ä¸Šä¸€å€‹å‘½ä»¤çš„åŸ·è¡Œçµæœ

---

## ğŸŒŸ ä¸»é¡Œå››ï¼šlog åˆ†ææŠ€å·§

#### å¸¸ç”¨åˆ†æå‘½ä»¤
```bash
# å°‹æ‰¾ç‰¹å®šå­—ä¸²
grep "ERROR" app.log

# è¨ˆç®—å‡ºç¾æ¬¡æ•¸
grep -c "ERROR" app.log

# å°‹æ‰¾å‰å¾Œè¡Œ
grep -A 2 -B 2 "ERROR" app.log

# å°‹æ‰¾å¤šå€‹æª”æ¡ˆ
grep "ERROR" *.log
for f in logs/*.log; do grep -q "ERROR" "$f" && echo "$f æœ‰éŒ¯"; done

# å°‹æ‰¾æ™‚é–“ç¯„åœ
sed -n '/2023-01-01 10:00:00/,/2023-01-01 11:00:00/p' app.log

# çµ±è¨ˆ HTTP ç‹€æ…‹ç¢¼
awk '{print $9}' access.log | sort | uniq -c | sort -rn
```

### ğŸ“Š ä¸»é¡Œå››ï¼šlog åˆ†æå¯¦æˆ°

#### ğŸ” æƒ…å¢ƒä¸€ï¼šåˆ†æ Web ä¼ºæœå™¨è«å•æ¨¡å¼èˆ‡æ•ˆèƒ½å•é¡Œ

**æƒ…å¢ƒèªªæ˜ï¼š**
ä½ çš„ Web æ‡‰ç”¨ç¨‹å¼è¿‘æœŸå‡ºç¾æ•ˆèƒ½ä¸‹é™ï¼Œéœ€è¦åˆ†æ Nginx çš„è«å•æ—¥èªŒä¾†æ‰¾å‡ºåŸå› ã€‚

```bash
# æ­¥é©Ÿ 1: åˆ†æè«å•é‡è·Ÿç‹€æ…‹ç¢¼åˆ†ä½ˆ
# æ¯å°æ™‚è«å•é‡
awk '{print substr($4, 2, 13)}' /var/log/nginx/access.log | sort | uniq -c

# è¼¸å‡ºçµæœç¯„ä¾‹
#   156 01/Mar/2023:00
#   243 01/Mar/2023:01
#  1503 01/Mar/2023:02  <- å°–å³°æ™‚æ®µ

# æ­¥é©Ÿ 2: æŸ¥çœ‹ HTTP ç‹€æ…‹ç¢¼åˆ†ä½ˆ
awk '{print $9}' /var/log/nginx/access.log | sort | uniq -c | sort -rn

# è¼¸å‡ºçµæœç¯„ä¾‹
# 15234 200
#  1503 301
#   782 404
#   543 500  <- æœå‹™å™¨å…§éƒ¨éŒ¯èª¤

# æ­¥é©Ÿ 3: æ‰¾å‡ºå“ªäº› URL é€ æˆ 500 éŒ¯èª¤
awk '$9 == 500 {print $7}' /var/log/nginx/access.log | sort | uniq -c | sort -rn | head -10

# è¼¸å‡ºçµæœç¯„ä¾‹
#  342 /api/reports/generate
#  156 /api/users/profile

# æ­¥é©Ÿ 4: æŸ¥çœ‹æŸå€‹ç‰¹å®š URL çš„éŸ¿æ‡‰æ™‚é–“
awk '$7 == "/api/reports/generate" {print $7, $10}' /var/log/nginx/access.log | sort -nk2 | tail

# è¼¸å‡ºçµæœç¯„ä¾‹ (ç¬¬äºŒæ¬„æ˜¯éŸ¿æ‡‰æ™‚é–“ï¼Œå–®ä½ç‚ºæ¯«ç§’)
# /api/reports/generate 1243
# /api/reports/generate 2851
# /api/reports/generate 5231  <- éå¸¸æ…¢çš„è«å•
```

**æŠ€è¡“è§£é‡‹ï¼š**
- `awk '{print substr($4, 2, 13)}'`ï¼šæ“·å–æ—¥æœŸæ™‚é–“æ¬„ä½çš„å°æ™‚éƒ¨åˆ†
- `sort | uniq -c`ï¼šè¨ˆç®—æ¯å°æ™‚çš„è«å•æ¬¡æ•¸
- `$9 == 500`ï¼šç¯©é¸ HTTP 500 ç‹€æ…‹ç¢¼çš„è«å•
- `sort -rn`ï¼šä¾æ•¸å­—é™åºæ’åºï¼ˆæœ€å¤šçš„åœ¨å‰é¢ï¼‰
- `sort -nk2`ï¼šä¾ç¬¬äºŒæ¬„çš„æ•¸å­—å‡åºæ’åº

#### ğŸ” æƒ…å¢ƒäºŒï¼šåˆ†ææ‡‰ç”¨ç¨‹å¼éŒ¯èª¤æ—¥èªŒæ‰¾å‡ºç³»çµ±ç•°å¸¸

**æƒ…å¢ƒèªªæ˜ï¼š**
ä½ çš„ Java æ‡‰ç”¨ç¨‹å¼åœ¨æ·±å¤œå‡ºç¾ç•°å¸¸ä¸­æ­¢ï¼Œéœ€è¦å¿«é€Ÿåˆ†ææ—¥èªŒæª”æ‰¾å‡ºåŸå› ã€‚

```bash
# æ­¥é©Ÿ 1: å°‹æ‰¾ç•°å¸¸ç™¼ç”Ÿçš„æ™‚é–“é»
grep -n "Exception\|Error" /var/log/app/application.log | head

# è¼¸å‡ºçµæœç¯„ä¾‹
# 15876:2023-03-02 01:45:23 ERROR [ThreadPoolExecutor-3] - java.lang.OutOfMemoryError: Java heap space

# æ­¥é©Ÿ 2: æŸ¥çœ‹ç•°å¸¸ç™¼ç”Ÿå‰å¾Œçš„æ—¥èªŒ
grep -n -A 10 -B 5 "OutOfMemoryError" /var/log/app/application.log

# æ­¥é©Ÿ 3: åˆ†æè¨˜æ†¶é«”ä½¿ç”¨æƒ…æ³
grep "Memory usage" /var/log/app/application.log | tail -50 > memory_usage.txt

# æ­¥é©Ÿ 4: å°‹æ‰¾ç‰¹å®šçš„å¤§å‹æ“ä½œ
grep "Processing large dataset" /var/log/app/application.log | grep "$(date -d yesterday +%F)" | wc -l

# æ­¥é©Ÿ 5: å°‹æ‰¾ç•°å¸¸ç™¼ç”Ÿå‰çš„ç‰¹å®šæ“ä½œ
sed -n '/2023-03-02 01:30:00/,/2023-03-02 01:45:23/p' /var/log/app/application.log | grep "dataset\|batch\|memory" > events_before_crash.log
```

**æŠ€è¡“è§£é‡‹ï¼š**
- `grep -n`ï¼šé¡¯ç¤ºè¡Œè™Ÿï¼Œå¹«åŠ©å®šä½å•é¡Œ
- `grep -A 10 -B 5`ï¼šé¡¯ç¤ºç¬¦åˆæ¢ä»¶è¡Œçš„å‰ 5 è¡Œå’Œå¾Œ 10 è¡Œ
- `grep "$(date -d yesterday +%F)"`ï¼šå°‹æ‰¾æ˜¨å¤©çš„æ—¥æœŸè¨˜éŒ„
- `sed -n '/start_time/,/end_time/p'`ï¼šæ“·å–æŒ‡å®šæ™‚é–“ç¯„åœçš„æ—¥èªŒ

#### ğŸ” æƒ…å¢ƒä¸‰ï¼šå»ºç«‹æ—¥èªŒåˆ†æè…³æœ¬ä½œç‚ºç›£æ§å·¥å…·

**æƒ…å¢ƒèªªæ˜ï¼š**
ä½ éœ€è¦å»ºç«‹ä¸€å€‹è‡ªå‹•åŒ–è…³æœ¬ï¼Œå®šæœŸåˆ†ææ—¥èªŒæª”ä¸¦ç”Ÿæˆå ±è¡¨ï¼Œå¦‚æœç™¼ç¾å¼‚å¸¸æƒ…æ³å‰‡ç™¼é€è­¦å ±ã€‚

```bash
#!/bin/bash
# log_analyzer.sh

LOG_DIR="/var/log/app"
REPORT_DIR="/var/reports"
DATE=$(date +%F)
ALERT_THRESHOLD=50  # éŒ¯èª¤æ•¸é‡è­¦åˆ¤é–€æª»

# ç¢ºä¿å ±è¡¨ç›®éŒ„å­˜åœ¨
mkdir -p $REPORT_DIR

# å‰µå»ºå ±è¡¨æª”æ¡ˆ
REPORT_FILE="$REPORT_DIR/log_report_$DATE.txt"

echo "=== æ—¥èªŒåˆ†æå ±è¡¨ - $DATE ===" > $REPORT_FILE
echo "" >> $REPORT_FILE

# 1. çµ±è¨ˆéŒ¯èª¤å’Œè­¦å‘Šæ•¸é‡
echo "1. éŒ¯èª¤å’Œè­¦å‘Šçµ±è¨ˆ" >> $REPORT_FILE
ERROR_COUNT=$(grep -c "ERROR" $LOG_DIR/application.log)
WARN_COUNT=$(grep -c "WARN" $LOG_DIR/application.log)

echo "   éŒ¯èª¤ (ERROR): $ERROR_COUNT" >> $REPORT_FILE
echo "   è­¦å‘Š (WARN): $WARN_COUNT" >> $REPORT_FILE
echo "" >> $REPORT_FILE

# 2. å‰ 10 å€‹æœ€å¸¸è¦‹çš„éŒ¯èª¤
echo "2. æœ€å¸¸è¦‹çš„éŒ¯èª¤é¡å‹" >> $REPORT_FILE
grep "ERROR" $LOG_DIR/application.log | awk -F "ERROR" '{print $2}' | cut -d ':' -f1 | sort | uniq -c | sort -rn | head -10 >> $REPORT_FILE
echo "" >> $REPORT_FILE

# 3. æ¯å°æ™‚éŒ¯èª¤åˆ†ä½ˆ
echo "3. æ¯å°æ™‚éŒ¯èª¤åˆ†ä½ˆ" >> $REPORT_FILE
grep "ERROR" $LOG_DIR/application.log | awk '{print substr($1,1,13)}' | sort | uniq -c >> $REPORT_FILE
echo "" >> $REPORT_FILE

# 4. ç³»çµ±æ•ˆèƒ½æŒ‡æ¨™
echo "4. æ•ˆèƒ½æŒ‡æ¨™" >> $REPORT_FILE
echo "   å¹³å‡éŸ¿æ‡‰æ™‚é–“: $(grep "Response time" $LOG_DIR/application.log | awk '{sum+=$NF; count++} END {print sum/count "ms"}')" >> $REPORT_FILE
echo "   æœ€å¤§éŸ¿æ‡‰æ™‚é–“: $(grep "Response time" $LOG_DIR/application.log | awk '{print $NF}' | sort -n | tail -1) ms" >> $REPORT_FILE
echo "   äº¤æ˜“ç¸½æ•¸: $(grep -c "Transaction completed" $LOG_DIR/application.log)" >> $REPORT_FILE
echo "" >> $REPORT_FILE

# 5. æª¢æŸ¥æ˜¯å¦éœ€è¦ç™¼é€è­¦å ±
if [ $ERROR_COUNT -gt $ALERT_THRESHOLD ]; then
    echo "[è­¦å ±] éŒ¯èª¤æ•¸é‡ ($ERROR_COUNT) è¶…éé–€æª»å€¼ $ALERT_THRESHOLD"
    
    # ç™¼é€é›»å­éƒµä»¶è­¦å ±
    cat $REPORT_FILE | mail -s "[è­¦å ±] æ—¥èªŒåˆ†æå ±è¡¨ - éŒ¯èª¤æ•¸é‡è¶…æ¨™ - $DATE" admin@example.com
    
    # æˆ–ç™¼é€ Slack è­¦å ±
    curl -X POST -H "Content-Type: application/json" \
         -d "{\"text\":\"[è­¦å ±] æ—¥èªŒåˆ†æç™¼ç¾ $ERROR_COUNT å€‹éŒ¯èª¤ï¼Œè¶…éé–€æª»å€¼ $ALERT_THRESHOLD\"}" \
         https://hooks.slack.com/services/YOUR_WEBHOOK_URL
fi

echo "å ±è¡¨å·²ç”Ÿæˆ: $REPORT_FILE"
```

**ä½¿ç”¨æ–¹å¼ï¼š**
```bash
# æ‰‹å‹•åŸ·è¡Œåˆ†æ
./log_analyzer.sh

# è¨­å®šç‚ºæ¯æ—¥è‡ªå‹•åŸ·è¡Œ
0 7 * * * /path/to/log_analyzer.sh
```

**æŠ€è¡“è§£é‡‹ï¼š**
- `grep -c`ï¼šè¨ˆç®—ç¬¦åˆæ¢ä»¶çš„è¡Œæ•¸
- `awk -F`ï¼šæŒ‡å®šæ¬„ä½åˆ†éš”ç¬¦
- `awk '{sum+=$NF; count++} END {print sum/count}'`ï¼šè¨ˆç®—å¹³å‡å€¼
- `mail -s`ï¼šç™¼é€é›»å­éƒµä»¶è­¦å ±
- `curl -X POST`ï¼šç™¼é€ webhook é€šçŸ¥

### ğŸ“Š æ—¥èªŒç®¡ç†é€²éšæŠ€å·§

#### logrotate é…ç½®
```bash
# /etc/logrotate.d/myapp
/var/log/myapp/*.log {
    daily
    rotate 7
    compress
    delaycompress
    missingok
    notifempty
    create 0640 user group
    postrotate
        systemctl reload myapp
    endscript
}
```

#### journalctl é€²éšä½¿ç”¨
```bash
# æŒ‰æ™‚é–“æŸ¥è©¢
journalctl --since "2023-01-01" --until "2023-01-02"

# æŒ‰æœå‹™æŸ¥è©¢
journalctl -u nginx.service

# æŒ‰å„ªå…ˆç´šæŸ¥è©¢
journalctl -p err

# å¯¦æ™‚è¿½è¹¤
journalctl -f -u myapp.service
```

#### æ—¥èªŒåˆ†æè…³æœ¬ç¯„ä¾‹
```bash
#!/bin/bash
# log_analyzer.sh

LOG_DIR="/var/log/myapp"
REPORT_FILE="report_$(date +%F).txt"

echo "===== éŒ¯èª¤çµ±è¨ˆ =====" > $REPORT_FILE
grep -c "ERROR" $LOG_DIR/*.log >> $REPORT_FILE

echo -e "\n===== æœ€å¸¸è¦‹çš„éŒ¯èª¤ =====" >> $REPORT_FILE
grep "ERROR" $LOG_DIR/*.log | awk -F': ' '{print $2}' | sort | uniq -c | sort -nr | head -5 >> $REPORT_FILE

echo -e "\n===== éŒ¯èª¤ç™¼ç”Ÿæ™‚é–“åˆ†å¸ƒ =====" >> $REPORT_FILE
grep "ERROR" $LOG_DIR/*.log | awk '{print $1}' | cut -d'T' -f2 | cut -d':' -f1 | sort | uniq -c >> $REPORT_FILE
```

---

## ğŸŒŸ ä¸»é¡Œäº”ï¼šå®‰å…¨æ€§åŸºç¤å¯¦è¸

### ğŸ”’ SSH é‡‘é‘°ç®¡ç†
```bash
# ç”Ÿæˆ SSH é‡‘é‘°
ssh-keygen -t ed25519 -C "your_email@example.com"

# è¤‡è£½å…¬é‘°åˆ°é ç«¯ä¼ºæœå™¨
ssh-copy-id user@remote-server

# ä½¿ç”¨é‡‘é‘°ç™»å…¥
ssh -i ~/.ssh/id_ed25519 user@remote-server
```

#### ğŸ” æƒ…å¢ƒä¸€ï¼šå»ºç«‹å®‰å…¨çš„ SSH é‡‘é‘°èªè­‰æ©Ÿåˆ¶

**æƒ…å¢ƒèªªæ˜ï¼š**
ä½ éœ€è¦ç‚ºå¤šå°æ•¸æ“šåº«ä¼ºæœå™¨è¨­å®šå®‰å…¨çš„ç„¡å¯†ç¢¼ SSH é€£ç·šï¼Œä¸¦ç¢ºä¿åªæœ‰æˆæ¬Šçš„ç®¡ç†å“¡å¯ä»¥å­˜å–ã€‚

```bash
# æ­¥é©Ÿ 1: ç”¢ç”Ÿå¼·å¯†é‘°å°ï¼ˆä½¿ç”¨ ED25519 æ¼”ç®—æ³•ï¼‰
ssh-keygen -t ed25519 -C "dataengineer@company.com"
# æˆ–è€…ä½¿ç”¨ RSA ä½†è¦æŒ‡å®šé«˜ä½å…ƒ
ssh-keygen -t rsa -b 4096 -C "dataengineer@company.com"

# æ­¥é©Ÿ 2: å°‡å…¬é‘°å‚³é€åˆ°æ‰€æœ‰éœ€è¦ç®¡ç†çš„ä¼ºæœå™¨
ssh-copy-id -i ~/.ssh/id_ed25519.pub user@db1.example.com
ssh-copy-id -i ~/.ssh/id_ed25519.pub user@db2.example.com

# æ­¥é©Ÿ 3: åœ¨é ç«¯ä¼ºæœå™¨ä¸Šå¼·åŒ– SSH è¨­å®š
sudo nano /etc/ssh/sshd_config

# ä¿®æ”¹ä»¥ä¸‹è¨­å®š
# PasswordAuthentication no        # ç¦ç”¨å¯†ç¢¼ç™»å…¥
# PermitRootLogin prohibit-password # ç¦æ­¢ root ä½¿ç”¨å¯†ç¢¼ç™»å…¥
# Protocol 2                       # åªä½¿ç”¨ SSH å”è­°ç¬¬ 2 ç‰ˆ

# æ­¥é©Ÿ 4: é‡å•Ÿ SSH æœå‹™ä½¿è¨­å®šç”Ÿæ•ˆ
sudo systemctl restart sshd

# æ­¥é©Ÿ 5: å‰µå»º SSH é…ç½®æª”æ¡ˆç°¡åŒ–é€£ç·š
cat >> ~/.ssh/config << 'EOF'
Host db1
    HostName db1.example.com
    User datauser
    IdentityFile ~/.ssh/id_ed25519
    Port 22

Host db2
    HostName db2.example.com
    User datauser
    IdentityFile ~/.ssh/id_ed25519
    Port 22
EOF

chmod 600 ~/.ssh/config  # è¨­å®šæ­£ç¢ºçš„æ¬Šé™

# æ­¥é©Ÿ 6: ç¾åœ¨å¯ä»¥ä½¿ç”¨ç°¡åŒ–å‘½ä»¤é€£ç·š
ssh db1  # ç­‰åŒæ–¼ ssh -i ~/.ssh/id_ed25519 datauser@db1.example.com
```

**æŠ€è¡“è§£é‡‹ï¼š**
- `ssh-keygen -t ed25519`ï¼šä½¿ç”¨ç¾ä»£çš„ ED25519 æ¼”ç®—æ³•ç”¢ç”Ÿå¯†é‘°å°ï¼Œæ¯” RSA æ›´å®‰å…¨ä¸”æ›´çŸ­
- `ssh-copy-id`ï¼šè‡ªå‹•å°‡å…¬é‘°åŠ åˆ°é ç«¯ä¼ºæœå™¨çš„ `~/.ssh/authorized_keys` æª”æ¡ˆ
- `PasswordAuthentication no`ï¼šå¼·åˆ¶ä½¿ç”¨é‡‘é‘°èªè­‰ï¼Œé˜²æ­¢æš´åŠ›ç ´è§£å¯†ç¢¼
- `~/.ssh/config`ï¼šç°¡åŒ– SSH é€£ç·šè¨­å®šï¼Œä¸éœ€è¦è¨˜æ†¶è¤‡é›œçš„é€£ç·šåƒæ•¸

### ğŸ›¡ï¸ æª”æ¡ˆæ¬Šé™æœ€ä½³å¯¦è¸
```bash
# æ•æ„Ÿæª”æ¡ˆè¨­å®šåš´æ ¼æ¬Šé™
chmod 600 ~/.ssh/id_rsa          # ç§é‘°åªæœ‰æ“æœ‰è€…å¯è®€å¯«
chmod 644 ~/.ssh/id_rsa.pub      # å…¬é‘°æ‰€æœ‰äººå¯è®€

# è…³æœ¬åŸ·è¡Œæ¬Šé™
chmod 755 /scripts/*.sh          # è…³æœ¬å¯åŸ·è¡Œä½†åªæœ‰æ“æœ‰è€…å¯å¯«

# è³‡æ–™ç›®éŒ„æ¬Šé™
chmod -R 750 /data               # ç›®éŒ„å¯è®€å¯åŸ·è¡Œä½†ä¸å¯å¯«çµ¦å…¶ä»–äºº
```

#### ğŸ” æƒ…å¢ƒäºŒï¼šç‚ºå…±ç”¨æ•¸æ“šåº«è¨­å®šå®‰å…¨çš„æª”æ¡ˆæ¬Šé™

**æƒ…å¢ƒèªªæ˜ï¼š**
ä½ çš„åœ˜éšŠéœ€è¦åœ¨ä¸€å€‹å…±ç”¨çš„ Linux ä¼ºæœå™¨ä¸Šè¨­å®šä¸€å€‹æ•¸æ“šåˆ†æå·¥ä½œå€ï¼Œä½¿ä¸åŒè§’è‰²çš„äººå¯ä»¥å®‰å…¨åœ°å­˜å–å’Œè™•ç†æ•¸æ“šã€‚

```bash
# æ­¥é©Ÿ 1: å‰µå»ºç¾¤çµ„å’Œç”¨æˆ¶
# å‰µå»ºç¾¤çµ„
sudo groupadd data_analysts
sudo groupadd data_scientists
sudo groupadd data_engineers

# å‰µå»ºç”¨æˆ¶ä¸¦æŒ‡å®šä¸»ç¾¤çµ„
sudo useradd -m -g data_analysts -s /bin/bash analyst1
sudo useradd -m -g data_scientists -s /bin/bash scientist1
sudo useradd -m -g data_engineers -s /bin/bash engineer1

# è¨­å®šå¯†ç¢¼
sudo passwd analyst1
sudo passwd scientist1
sudo passwd engineer1

# æ­¥é©Ÿ 2: å‰µå»ºè³‡æ–™ç›®éŒ„çµæ§‹
sudo mkdir -p /data/raw           # åŸå§‹æ•¸æ“š
sudo mkdir -p /data/processed     # è™•ç†å¾Œçš„æ•¸æ“š
sudo mkdir -p /data/analytics     # åˆ†æçµæœ
sudo mkdir -p /data/scripts       # è…³æœ¬ç›®éŒ„

# æ­¥é©Ÿ 3: è¨­å®šç›®éŒ„æ¬Šé™
# è¨­å®šæ ¹ç›®éŒ„æ“æœ‰è€…ç‚º rootï¼Œç¾¤çµ„ç‚º data_engineers
sudo chown -R root:data_engineers /data

# è¨­å®šåŸºæœ¬æ¬Šé™
sudo chmod 750 /data              # drwxr-x--- ç›®éŒ„æ“æœ‰è€…å¯è®€å¯«åŸ·è¡Œï¼Œç¾¤çµ„å¯è®€åŸ·è¡Œ

# raw ç›®éŒ„ï¼šåªæœ‰ data_engineers å¯å¯«
sudo chmod 770 /data/raw          # drwxrwx--- åªæœ‰ data_engineers å¯å¯«

# processed ç›®éŒ„ï¼šæ‰€æœ‰ç¾¤çµ„å¯è®€ï¼Œdata_engineers å’Œ data_scientists å¯å¯«
sudo chown -R root:data_engineers /data/processed
sudo chmod 770 /data/processed    # drwxrwx---
sudo setfacl -m g:data_scientists:rwx /data/processed  # çµ¦ data_scientists ç¾¤çµ„è®€å¯«åŸ·è¡Œæ¬Šé™

# analytics ç›®éŒ„ï¼šæ‰€æœ‰ç¾¤çµ„å¯è®€ï¼Œdata_analysts å¯å¯«
sudo chown -R root:data_analysts /data/analytics
sudo chmod 770 /data/analytics    # drwxrwx---

# scripts ç›®éŒ„ï¼šåªæœ‰ data_engineers å¯å¯«ï¼Œä½†æ‰€æœ‰äººå¯åŸ·è¡Œ
sudo chown -R root:data_engineers /data/scripts
sudo chmod 755 /data/scripts      # drwxr-xr-x

# æ­¥é©Ÿ 4: è¨­å®šè…³æœ¬æª”æ¡ˆæ¬Šé™
sudo find /data/scripts -type f -name "*.sh" -exec chmod 755 {} \;  # è…³æœ¬å¯åŸ·è¡Œ

# æ­¥é©Ÿ 5: å‰µå»ºå…±ç”¨ç›®éŒ„ä¸¦è¨­å®š SGID ä½
sudo mkdir -p /data/shared
sudo chown root:data_engineers /data/shared
sudo chmod 2775 /data/shared      # drwxrwsr-x è¨­å®š SGIDï¼Œç¢ºä¿æ–°å‰µå»ºçš„æª”æ¡ˆç¹¼æ‰¿ç¾¤çµ„

# ç‚ºå…¶ä»–ç¾¤çµ„å¢åŠ å­˜å–æ¬Šé™
sudo setfacl -m g:data_scientists:rwx /data/shared
sudo setfacl -m g:data_analysts:rx /data/shared
```

**æŠ€è¡“è§£é‡‹ï¼š**
- `chmod 750`ï¼šè¨­å®šæ¬Šé™ç‚º `rwxr-x---`ï¼Œå³æ“æœ‰è€…å¯è®€å¯«åŸ·è¡Œï¼Œç¾¤çµ„å¯è®€åŸ·è¡Œï¼Œå…¶ä»–äººç„¡æ¬Šé™
- `chown user:group`ï¼šè®Šæ›´æª”æ¡ˆæˆ–ç›®éŒ„çš„æ“æœ‰è€…å’Œç¾¤çµ„
- `chmod 2775`ï¼šè¨­å®š SGID ä½ï¼Œç¢ºä¿åœ¨ç›®éŒ„ä¸­å‰µå»ºçš„æ–°æª”æ¡ˆç¹¼æ‰¿ç›®éŒ„çš„ç¾¤çµ„
- `setfacl`ï¼šè¨­å®šå­˜å–æ§åˆ¶æ¸…å–® (ACL)ï¼Œæä¾›æ›´ç²¾ç´°çš„æ¬Šé™æ§åˆ¶
- `find ... -exec`ï¼šå°‹æ‰¾æ‰€æœ‰ç¬¦åˆæ¢ä»¶çš„æª”æ¡ˆä¸¦åŸ·è¡ŒæŒ‡å®šçš„å‘½ä»¤

### ğŸ” å®‰å…¨æ€§æª¢æŸ¥è…³æœ¬
```bash
#!/bin/bash
# security_check.sh

echo "æª¢æŸ¥é–‹æ”¾çš„ç¶²è·¯é€£æ¥..."
netstat -tuln

echo "æª¢æŸ¥å¯ç–‘çš„ cron ä»»å‹™..."
for user in $(cut -f1 -d: /etc/passwd); do
  crontab -u $user -l 2>/dev/null
done

echo "æª¢æŸ¥æ•æ„Ÿæª”æ¡ˆæ¬Šé™..."
find /home -name "*.pem" -o -name "*.key" | xargs ls -la
```

#### ğŸ” æƒ…å¢ƒä¸‰ï¼šå»ºç«‹å®šæœŸå®‰å…¨æª¢æŸ¥è…³æœ¬ä¿è­·æ•¸æ“šä¼ºæœå™¨

**æƒ…å¢ƒèªªæ˜ï¼š**
ä½œç‚ºä¸€åè³‡æ–™å·¥ç¨‹å¸«ï¼Œä½ éœ€è¦ç‚ºå…¬å¸çš„æ•¸æ“šè™•ç†ä¼ºæœå™¨å»ºç«‹ä¸€å€‹å…¨é¢çš„å®‰å…¨æª¢æŸ¥è…³æœ¬ï¼Œå®šæœŸæª¢æŸ¥æ¼æ´ä¸¦ç™¼é€å ±å‘Šã€‚

```bash
#!/bin/bash
# comprehensive_security_check.sh

# è¨­å®šè®Šæ•¸
HOSTNAME=$(hostname)
DATE=$(date +"%Y-%m-%d %H:%M:%S")
REPORT_FILE="/var/log/security/security_report_$(date +%F).txt"
EMAIL="security@company.com"

# ç¢ºä¿æ—¥èªŒç›®éŒ„å­˜åœ¨
mkdir -p /var/log/security

# é–‹å§‹å ±å‘Š
echo "========================================" > $REPORT_FILE
echo "   å®‰å…¨æª¢æŸ¥å ±å‘Š - $HOSTNAME" >> $REPORT_FILE
echo "   ç”Ÿæˆæ™‚é–“: $DATE" >> $REPORT_FILE
echo "========================================" >> $REPORT_FILE
echo "" >> $REPORT_FILE

# 1. æª¢æŸ¥ç³»çµ±æ›´æ–°
echo "1. ç³»çµ±æ›´æ–°ç‹€æ…‹" >> $REPORT_FILE
echo "----------------------------" >> $REPORT_FILE
apt list --upgradable 2>/dev/null | grep -v "Listing..." >> $REPORT_FILE
echo "" >> $REPORT_FILE

# 2. æª¢æŸ¥é–‹æ”¾çš„ç¶²è·¯é€£æ¥
echo "2. é–‹æ”¾çš„ç¶²è·¯é€£æ¥" >> $REPORT_FILE
echo "----------------------------" >> $REPORT_FILE
netstat -tuln | grep LISTEN >> $REPORT_FILE
echo "" >> $REPORT_FILE

# 3. æª¢æŸ¥å¾å¤–éƒ¨å¯å­˜å–çš„æœå‹™
echo "3. å¾å¤–éƒ¨å¯å­˜å–çš„æœå‹™" >> $REPORT_FILE
echo "----------------------------" >> $REPORT_FILE
netstat -tuln | grep LISTEN | grep -v "127.0.0.1" | grep -v "::1" >> $REPORT_FILE
echo "" >> $REPORT_FILE

# 4. æª¢æŸ¥æœ€è¿‘çš„ç™»å…¥å¤±æ•—å˜—è©¦
echo "4. æœ€è¿‘çš„ç™»å…¥å¤±æ•—å˜—è©¦" >> $REPORT_FILE
echo "----------------------------" >> $REPORT_FILE
grep "Failed password" /var/log/auth.log | tail -20 >> $REPORT_FILE
echo "" >> $REPORT_FILE

# 5. æª¢æŸ¥æœ€è¿‘çš„ sudo ä½¿ç”¨
echo "5. æœ€è¿‘çš„ sudo ä½¿ç”¨" >> $REPORT_FILE
echo "----------------------------" >> $REPORT_FILE
grep "sudo:" /var/log/auth.log | tail -20 >> $REPORT_FILE
echo "" >> $REPORT_FILE

# 6. æª¢æŸ¥ä½¿ç”¨è€…å¸³è™Ÿ
echo "6. ç³»çµ±ä½¿ç”¨è€…å¸³è™Ÿ" >> $REPORT_FILE
echo "----------------------------" >> $REPORT_FILE
echo "æœ‰ç™»å…¥ shell çš„ä½¿ç”¨è€…:" >> $REPORT_FILE
grep -v "/usr/sbin/nologin\|/bin/false" /etc/passwd | cut -d: -f1 >> $REPORT_FILE
echo "" >> $REPORT_FILE

# 7. æª¢æŸ¥ cron ä»»å‹™
echo "7. æ‰€æœ‰ä½¿ç”¨è€…çš„ cron ä»»å‹™" >> $REPORT_FILE
echo "----------------------------" >> $REPORT_FILE
for user in $(cut -f1 -d: /etc/passwd); do
  crontab_output=$(crontab -u $user -l 2>/dev/null)
  if [ ! -z "$crontab_output" ]; then
    echo "$user çš„ cron ä»»å‹™:" >> $REPORT_FILE
    echo "$crontab_output" >> $REPORT_FILE
    echo "" >> $REPORT_FILE
  fi
done

# 8. æª¢æŸ¥æ•æ„Ÿæª”æ¡ˆæ¬Šé™
echo "8. æ•æ„Ÿæª”æ¡ˆæ¬Šé™" >> $REPORT_FILE
echo "----------------------------" >> $REPORT_FILE
echo "SSH é‡‘é‘°:" >> $REPORT_FILE
find /home -name "id_rsa" -o -name "*.pem" -o -name "*.key" | xargs ls -la 2>/dev/null >> $REPORT_FILE
echo "" >> $REPORT_FILE

# 9. æª¢æŸ¥ä¸–ç•Œå¯å¯«çš„ç›®éŒ„
echo "9. ä¸–ç•Œå¯å¯«çš„ç›®éŒ„" >> $REPORT_FILE
echo "----------------------------" >> $REPORT_FILE
find / -type d -perm -o+w -not -path "/proc/*" -not -path "/sys/*" -not -path "/dev/*" 2>/dev/null >> $REPORT_FILE
echo "" >> $REPORT_FILE

# 10. æª¢æŸ¥ç„¡æ“æœ‰è€…çš„æª”æ¡ˆ
echo "10. ç„¡æ“æœ‰è€…çš„æª”æ¡ˆ" >> $REPORT_FILE
echo "----------------------------" >> $REPORT_FILE
find / -nouser -o -nogroup -not -path "/proc/*" -not -path "/sys/*" 2>/dev/null | head -20 >> $REPORT_FILE
echo "" >> $REPORT_FILE

# 11. æª¢æŸ¥é˜²ç«ç‰†ç‹€æ…‹
echo "11. é˜²ç«ç‰†ç‹€æ…‹" >> $REPORT_FILE
echo "----------------------------" >> $REPORT_FILE
if command -v ufw >/dev/null 2>&1; then
  ufw status >> $REPORT_FILE
elif command -v iptables >/dev/null 2>&1; then
  iptables -L -n >> $REPORT_FILE
else
  echo "æœªå®‰è£é˜²ç«ç‰†æˆ–ç„¡æ³•æª¢æ¸¬" >> $REPORT_FILE
fi
echo "" >> $REPORT_FILE

# 12. æª¢æŸ¥ç£ç¢Ÿä½¿ç”¨æƒ…æ³
echo "12. ç£ç¢Ÿä½¿ç”¨æƒ…æ³" >> $REPORT_FILE
echo "----------------------------" >> $REPORT_FILE
df -h >> $REPORT_FILE
echo "" >> $REPORT_FILE

# 13. æª¢æŸ¥å¤§å‹æª”æ¡ˆ
echo "13. æœ€å¤§çš„ 10 å€‹æª”æ¡ˆ" >> $REPORT_FILE
echo "----------------------------" >> $REPORT_FILE
find / -type f -not -path "/proc/*" -not -path "/sys/*" -exec ls -lh {} \; 2>/dev/null | sort -k 5 -hr | head -10 >> $REPORT_FILE
echo "" >> $REPORT_FILE

# å¦‚æœç™¼ç¾å±éšªå•é¡Œï¼Œç™¼é€é›»å­éƒµä»¶è­¦å ±
if grep -q "Failed password" $REPORT_FILE || find / -perm -4000 -user root -not -path "/bin/*" -not -path "/sbin/*" -not -path "/usr/*" 2>/dev/null | grep -q .; then
  # å‰µå»ºè­¦å ±æ‘˜è¦
  SUMMARY_FILE="/tmp/security_summary.txt"
  echo "å®‰å…¨è­¦å ±: $HOSTNAME ç™¼ç¾æ½›åœ¨å®‰å…¨å•é¡Œ" > $SUMMARY_FILE
  echo "" >> $SUMMARY_FILE
  
  if grep -q "Failed password" $REPORT_FILE; then
    echo "ç™¼ç¾å¤šæ¬¡ç™»å…¥å¤±æ•—å˜—è©¦" >> $SUMMARY_FILE
    grep "Failed password" $REPORT_FILE | head -5 >> $SUMMARY_FILE
    echo "" >> $SUMMARY_FILE
  fi
  
  # ç™¼é€é›»å­éƒµä»¶è­¦å ±
  cat $SUMMARY_FILE | mail -s "å®‰å…¨è­¦å ±: $HOSTNAME" $EMAIL
  echo "å·²ç™¼é€è­¦å ±é›»å­éƒµä»¶åˆ° $EMAIL"
fi

echo "å®‰å…¨æª¢æŸ¥å®Œæˆï¼Œå ±å‘Šå·²å„²å­˜åˆ° $REPORT_FILE"
```

**è¨­å®šç‚ºæ¯æ—¥è‡ªå‹•åŸ·è¡Œï¼š**
```bash
# è¨­å®šæ¬Šé™
sudo chmod +x /path/to/comprehensive_security_check.sh

# å‰µå»º cron ä»»å‹™
sudo crontab -e

# æ¯æ—¥å‡Œæ™¨ 3 é»åŸ·è¡Œ
0 3 * * * /path/to/comprehensive_security_check.sh
```

**æŠ€è¡“è§£é‡‹ï¼š**
- `netstat -tuln`ï¼šé¡¯ç¤ºæ‰€æœ‰é–‹æ”¾çš„ TCP/UDP é€£æ¥åŸ 
- `grep "Failed password" /var/log/auth.log`ï¼šå°‹æ‰¾ç™»å…¥å¤±æ•—çš„å˜—è©¦è¨˜éŒ„
- `find / -perm -4000`ï¼šå°‹æ‰¾æ‰€æœ‰è¨­å®šäº† SUID ä½çš„æª”æ¡ˆï¼Œé€™äº›æª”æ¡ˆå¯èƒ½æœ‰å®‰å…¨é¢¨éšª
- `find / -type d -perm -o+w`ï¼šå°‹æ‰¾ä¸–ç•Œå¯å¯«çš„ç›®éŒ„ï¼Œé€™äº›ç›®éŒ„å¯èƒ½è¢«åˆ©ç”¨ä¾†å­˜æ”¾æƒ¡æ„è…³æœ¬
- `ufw status`ï¼šæª¢æŸ¥é˜²ç«ç‰†ç‹€æ…‹

é€™å€‹è…³æœ¬æä¾›äº†å…¨é¢çš„å®‰å…¨æª¢æŸ¥ï¼ŒåŒ…æ‹¬ç¶²è·¯é€£æ¥ã€ä½¿ç”¨è€…å¸³è™Ÿã€æª”æ¡ˆæ¬Šé™ã€ç™»å…¥å¤±æ•—å˜—è©¦ç­‰å¤šå€‹å®‰å…¨é¢å‘ã€‚å®šæœŸåŸ·è¡Œé€™å€‹è…³æœ¬å¯ä»¥å¹«åŠ©è³‡æ–™å·¥ç¨‹å¸«æå‰ç™¼ç¾æ½›åœ¨çš„å®‰å…¨å•é¡Œã€‚

---

## ğŸ Bonusï¼šå°ˆæ¡ˆå¯¦ä½œå°ç·´ç¿’

### âœ… CPU å£“åŠ›æ¸¬è©¦ Script
```python
# cpu_stress.py
while True:
    pass
```

ç”¨ä¾†ç·´ç¿’ top / ps / killï¼

---

## ğŸŒŸ ä¸»é¡Œå…­ï¼šETL è…³æœ¬å¯¦ä¾‹

### ğŸ“Š å®Œæ•´ ETL è™•ç†æµç¨‹ç¯„ä¾‹
```bash
#!/bin/bash
# etl_pipeline.sh

# è¨­å®šè®Šæ•¸
SOURCE_DIR="/data/source"
STAGING_DIR="/data/staging"
TARGET_DIR="/data/warehouse"
LOG_FILE="etl_$(date +%F).log"
ERROR_COUNT=0

# å‡½æ•¸ï¼šè¨˜éŒ„è¨Šæ¯
log_message() {
    echo "[$(date +'%Y-%m-%d %H:%M:%S')] $1" | tee -a $LOG_FILE
}

# å‡½æ•¸ï¼šéŒ¯èª¤è™•ç†
handle_error() {
    ERROR_COUNT=$((ERROR_COUNT + 1))
    log_message "éŒ¯èª¤: $1"
    
    # ç™¼é€éŒ¯èª¤é€šçŸ¥
    if [ $ERROR_COUNT -eq 1 ]; then
        curl -X POST -H "Content-Type: application/json" \
             -d "{\"text\":\"ETL éŒ¯èª¤: $1\"}" \
             https://hooks.slack.com/services/YOUR_WEBHOOK_URL
    fi
}

# å‡½æ•¸ï¼šè³‡æ–™æå–
extract_data() {
    log_message "é–‹å§‹è³‡æ–™æå–..."
    
    # å¾è³‡æ–™ä¾†æºä¸‹è¼‰æª”æ¡ˆ
    if wget -q -P $STAGING_DIR https://example.com/api/data.csv; then
        log_message "è³‡æ–™ä¸‹è¼‰æˆåŠŸ"
    else
        handle_error "è³‡æ–™ä¸‹è¼‰å¤±æ•—"
        return 1
    fi
    
    # å¾è³‡æ–™åº«åŒ¯å‡ºè³‡æ–™
    if psql -c "COPY (SELECT * FROM sales WHERE date = current_date - 1) TO '$STAGING_DIR/db_export.csv' WITH CSV HEADER"; then
        log_message "è³‡æ–™åº«åŒ¯å‡ºæˆåŠŸ"
    else
        handle_error "è³‡æ–™åº«åŒ¯å‡ºå¤±æ•—"
        return 1
    fi
    
    return 0
}

# å‡½æ•¸ï¼šè³‡æ–™è½‰æ›
transform_data() {
    log_message "é–‹å§‹è³‡æ–™è½‰æ›..."
    
    # ä½¿ç”¨ awk è™•ç† CSV æª”æ¡ˆ
    awk -F, 'NR>1 {sum[$1] += $2} END {for (region in sum) print region "," sum[region]}' \
        $STAGING_DIR/data.csv > $STAGING_DIR/transformed.csv
    
    if [ $? -eq 0 ]; then
        log_message "è³‡æ–™è½‰æ›æˆåŠŸ"
        return 0
    else
        handle_error "è³‡æ–™è½‰æ›å¤±æ•—"
        return 1
    fi
}

# å‡½æ•¸ï¼šè³‡æ–™è¼‰å…¥
load_data() {
    log_message "é–‹å§‹è³‡æ–™è¼‰å…¥..."
    
    # ç§»å‹•è™•ç†å¥½çš„æª”æ¡ˆåˆ°ç›®æ¨™ç›®éŒ„
    if mv $STAGING_DIR/transformed.csv $TARGET_DIR/data_$(date +%F).csv; then
        log_message "æª”æ¡ˆç§»å‹•æˆåŠŸ"
    else
        handle_error "æª”æ¡ˆç§»å‹•å¤±æ•—"
        return 1
    fi
    
    # è¼‰å…¥è³‡æ–™åˆ°è³‡æ–™åº«
    if psql -c "\\COPY summary_table FROM '$TARGET_DIR/data_$(date +%F).csv' WITH CSV"; then
        log_message "è³‡æ–™è¼‰å…¥è³‡æ–™åº«æˆåŠŸ"
    else
        handle_error "è³‡æ–™è¼‰å…¥è³‡æ–™åº«å¤±æ•—"
        return 1
    fi
    
    return 0
}

# ä¸»ç¨‹åº
main() {
    log_message "ETL æµç¨‹é–‹å§‹"
    
    # å»ºç«‹å¿…è¦çš„ç›®éŒ„
    mkdir -p $STAGING_DIR $TARGET_DIR
    
    # åŸ·è¡Œ ETL æµç¨‹
    if extract_data && transform_data && load_data; then
        log_message "ETL æµç¨‹æˆåŠŸå®Œæˆ"
        
        # æ¸…ç†æš«å­˜æª”æ¡ˆ
        rm -rf $STAGING_DIR/*
        
        # ç”¢ç”ŸæˆåŠŸå ±å‘Š
        echo "ETL æˆåŠŸå®Œæˆï¼Œè™•ç†æ™‚é–“: $(date)" > $TARGET_DIR/success_$(date +%F).txt
        
        return 0
    else
        log_message "ETL æµç¨‹å¤±æ•—ï¼ŒéŒ¯èª¤æ•¸: $ERROR_COUNT"
        return 1
    fi
}

# åŸ·è¡Œä¸»ç¨‹åº
main
exit $?
```

### ğŸ”„ çµåˆ cronã€log åˆ†æå’ŒéŒ¯èª¤è™•ç†
```bash
# crontab è¨­å®š
# 0 2 * * * /path/to/etl_pipeline.sh >> /var/log/etl/cron_$(date +\%F).log 2>&1

# éŒ¯èª¤ç›£æ§è…³æœ¬
#!/bin/bash
# monitor_etl.sh

LOG_DIR="/var/log/etl"
YESTERDAY=$(date -d "yesterday" +%F)
LOG_FILE="$LOG_DIR/cron_$YESTERDAY.log"

if grep -q "ETL æµç¨‹å¤±æ•—" $LOG_FILE; then
    echo "ETL æ˜¨æ—¥åŸ·è¡Œå¤±æ•—ï¼Œè©³ç´°è³‡è¨Šï¼š"
    grep -A 10 "éŒ¯èª¤:" $LOG_FILE
    
    # ç™¼é€è­¦å ±
    mail -s "ETL å¤±æ•—è­¦å ±" admin@example.com < $LOG_FILE
fi
```

---

## âœ… å»¶ä¼¸ä»»å‹™ï¼ˆDay2 Bonusï¼‰

- `for + parallel`ï¼šæ¨¡æ“¬ Spark ä¸¦è¡Œ map è™•ç†
- `config.env`ï¼šç”¨åƒæ•¸æ§åˆ¶è³‡æ–™ç¯„åœ
- æ ¹æ“š log æˆåŠŸèˆ‡å¦è‡ªå‹•ç§»å‹•æª”æ¡ˆ
- ç”¢ç”Ÿ CSV / HTML ç¸½ç´„å ±è¡¨
- GitLab CI/CD è‡ªå‹•åŒ–åŸ·è¡Œï¼Œæ¨¡æ“¬çœŸå¯¦æƒ…å¢ƒ
- ç™¼é€ Email é€šçŸ¥éŒ¯èª¤ï¼ˆå¯æ¥ webhookï¼‰

---

## ğŸ ç¸½çµï¼šDay 2 æŠ€èƒ½æ¨¹

- âœ… ç¨‹å¼èˆ‡è³‡æºè§€å¯Ÿ
- âœ… è‡ªå‹•æ’ç¨‹ cron ä»»å‹™
- âœ… å¯«å‡ºæµç¨‹æ§åˆ¶ Shell script
- âœ… åˆ†æéŒ¯èª¤èˆ‡ log æ¨¡æ“¬æ¸¬è©¦
- âœ… é–‹å§‹æ‰“é€ ä½ è‡ªå·±çš„è‡ªå‹•åŒ–è³‡æ–™è™•ç† pipelineï¼
- âœ… é€²éšç›£æ§å·¥å…·èˆ‡æŠ€å·§
- âœ… æ—¥èªŒç®¡ç†èˆ‡åˆ†æ
- âœ… Shell Script é€²éšåŠŸèƒ½
- âœ… åŸºæœ¬å®‰å…¨æ€§å¯¦è¸
- âœ… å®Œæ•´ ETL è…³æœ¬å¯¦ä¾‹
